{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Library"
      ],
      "metadata": {
        "id": "1f1F4gIBZQh3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pesLkzgKTK9T",
        "outputId": "b8474536-42cb-47f3-dee9-5d7c462b5730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as Data\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "_VWWZP1-Vz73"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Load dataset\n"
      ],
      "metadata": {
        "id": "ilZdnB2LXlx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist(batch_size):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "9kBMFVglXqGj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "train_MNIST, test_MNIST = load_mnist(batch_size)"
      ],
      "metadata": {
        "id": "X2tq7_LaX0_a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Create Fence GAN  accrodint got Architecture and hyperparameters on MNIST Dataset (Table 1)"
      ],
      "metadata": {
        "id": "SphKB5Hwbnsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Generatoro and Discriminator"
      ],
      "metadata": {
        "id": "GDKVWMZzzQX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100, 128 * 7 * 7),  # Assuming latent size of 100\n",
        "            nn.BatchNorm1d(128 * 7 * 7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Unflatten(1, (128, 7, 7)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 1, 4, stride=2, padding=1),\n",
        "            nn.Tanh()  # Output is a 28x28 image\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 7 * 7, 1024),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Linear(1024, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "gSVe1yMMqcUL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss"
      ],
      "metadata": {
        "id": "V1p6WAcLzVpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encirclement_loss(discriminator_outputs, alpha=0.1):\n",
        "    return torch.mean(torch.abs(discriminator_outputs - alpha))\n",
        "\n",
        "def dispersion_loss(generated_images, beta=30):\n",
        "    mean = torch.mean(generated_images, 0, keepdim=True)\n",
        "    return beta * torch.mean((generated_images - mean) ** 2)"
      ],
      "metadata": {
        "id": "6nR-NM9EqcW7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define optimization"
      ],
      "metadata": {
        "id": "jDGHrACTzarb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_G = optim.Adam(generator.parameters(), lr=2e-5, weight_decay=1e-4)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-5, weight_decay=1e-4)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "B8r5skRAzdnW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train model"
      ],
      "metadata": {
        "id": "Geom7qp6zebM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for i, (imgs, _) in enumerate(train_MNIST):\n",
        "        real_imgs = imgs\n",
        "        real = torch.ones(imgs.size(0), 1)\n",
        "        fake = torch.zeros(imgs.size(0), 1)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = criterion(discriminator(real_imgs), real)\n",
        "        z = torch.randn(imgs.size(0), 100)\n",
        "        fake_imgs = generator(z)\n",
        "        fake_loss = criterion(discriminator(fake_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss = criterion(discriminator(fake_imgs), real)\n",
        "        total_g_loss = g_loss + encirclement_loss(discriminator(fake_imgs)) + dispersion_loss(fake_imgs)\n",
        "        total_g_loss.backward()\n",
        "        optimizer_G.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUbDhateqcZi",
        "outputId": "cd31666d-40da-4579-96ae-8a4024b8f944"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [1:50:46<00:00, 66.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n"
      ],
      "metadata": {
        "id": "AFiZD_gGz8Xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_MNIST:\n",
        "\n",
        "        images = images\n",
        "        outputs = discriminator(images)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming the output is a probability of being real\n",
        "        total += images.size(0)\n",
        "        correct += (predicted == 1).sum().item()\n",
        "\n",
        "        z = torch.randn(images.size(0), 100)  # 100 is the size of the noise vector\n",
        "        fake_images = generator(z)\n",
        "        fake_outputs = discriminator(fake_images)\n",
        "        fake_predicted = (fake_outputs < 0.5).float()  # Fake images should be classified as 0\n",
        "        correct += (fake_predicted == 1).sum().item()\n",
        "        total += fake_images.size(0)\n",
        "\n",
        "print(f'Accuracy of the discriminator on the test images: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--1BYdCcqcce",
        "outputId": "831233eb-653f-4b4e-de6e-27ae71156ea7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the discriminator on the test images: 99.005%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save model"
      ],
      "metadata": {
        "id": "vGGQQN3-zrjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'generator'\n",
        "optimizer_path = 'generator_opt'\n",
        "torch.save(generator.state_dict(), model_path)\n",
        "torch.save(optimizer_G.state_dict(), optimizer_path)"
      ],
      "metadata": {
        "id": "m9w5jLixzycv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_model_path = 'discriminator'\n",
        "discriminator_optimizer_path = 'discriminator_opt'\n",
        "\n",
        "torch.save(discriminator.state_dict(), discriminator_model_path)\n",
        "torch.save(optimizer_D.state_dict(), discriminator_optimizer_path)"
      ],
      "metadata": {
        "id": "pqxSkv-Ciop-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9TQCpVJN0NKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}